{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request\n",
    "from litellm import completion\n",
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "ollama = Ollama(base_url='http://localhost:11434',\n",
    "model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docx(file):\n",
    "    doc = docx.Document(file)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5002\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [11/Mar/2024 13:54:10] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [11/Mar/2024 13:54:10] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [11/Mar/2024 13:54:44] \"POST /ask_question HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/ask_question', methods=['POST'])\n",
    "def ask_question():\n",
    "    question = request.form['question']\n",
    "    file_paths = request.files.getlist('files')\n",
    "    responses = []\n",
    "    \n",
    "    for file in file_paths:\n",
    "        if file.filename.endswith('.txt'):\n",
    "            content = file.read().decode('utf-8', 'ignore')\n",
    "        elif file.filename.endswith('.docx'):\n",
    "            content = read_docx(file)\n",
    "        else:\n",
    "            return render_template('error.html', message=\"Unsupported file format\")\n",
    "\n",
    "        try:\n",
    "            response = completion(model=\"ollama/llama2\", messages=[{\"content\": content, \"role\": \"user\"},{\"content\": question, \"role\": \"user\"}])\n",
    "            response_text = response.choices[0].message.content\n",
    "            responses.append((file.filename, response_text))\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error processing file {file.filename}: {str(e)}\"\n",
    "            responses.append((file.filename, error_message))\n",
    "\n",
    "    \n",
    "    return render_template('responses.html', question=question, responses=responses)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='127.0.0.1', port=5002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"C:/Users/a-elearoche/Documents/Continuum/Transcriptions/Transcription_test2_2024-02-15.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "oembed = OllamaEmbeddings(base_url=\"http://localhost:11434\", model=\"llama2\")\n",
    "datastore_directory = '../.datastore'\n",
    "vectorstore = Chroma.from_documents(documents=pages, embedding=oembed, persist_directory = datastore_directory)\n",
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Quelle est la premiere phrase du texte ? et la derniere ?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "qachain=RetrievalQA.from_chain_type(ollama, retriever=vectorstore.as_retriever())\n",
    "qachain({\"query\": question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
